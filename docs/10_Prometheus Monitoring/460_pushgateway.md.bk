
# Prometheus Push Gateway via Docker with some Python job

Le PushGateway est un service qui permet aux programmes de pousser leurs métriques plutôt que d'attendre que prometheus vienne les récupérer. Ce système est dédié aux jobs et programmes a durée de vie courte. Il faut l'utiliser seulement quand nécessaire car il ne respecte pas l'architecture normale de Prometheus.

- Documentation: https://prometheus.io/docs/practices/pushing/

## Mise en pratique

To get Grafana, Prometheus and a Push Gateway you can use the below:

```yaml
version: "3.9"

volumes:
    grafana-storage:

services:
    prometheus:
        image: prom/prometheus:latest
        ports:
            - "9090:9090"
        volumes:
          - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
        depends_on:
            - "prometheus-pushgateway"

    grafana:
        image: grafana/grafana:latest
        volumes:
            - grafana-storage:/var/lib/grafana
        ports:
            - "3000:3000"
        depends_on:
            - "prometheus"
        container_name: grafana

    prometheus-pushgateway:
        image: prom/pushgateway
        ports:
            - "9091:9091"
        container_name: prometheus-pushgateway
```

The prometheus config is very basic and really just tells prometheus to scrape the push gateway.

```yaml
global:
    scrape_interval: 15s

scrape_configs:
    - job_name: 'prometheus'
      scrape_interval: 5s
      static_configs:
          - targets: ['prometheus:9090']

    - job_name: 'pushgateway'
      honor_labels: true
      static_configs:
          - targets: ['prometheus-pushgateway:9091']
```

With those two in place just a quick `docker-compose up`` and we have a running test enviorment for what I needed.

# Python Code

The important thing is to setup your code to collect the metrics and then push them over to the push gateway.

To setup your code you will need to install the `prometheus_client` library.

`from prometheus_client import CollectorRegistry, Gauge, push_to_gateway`

After you import the correct items then it is time to use them. First you need to setup your registry of metrics:

`registry = CollectorRegistry()`

Now that you have that setup you can start creating metrics to track. I personally only used Gauges because of the data and usecase I had but you can certianly use others such as Counter, Text, etc. To create a Gauge you would do something like:

`sim_plans = Gauge("lte_sim_plans","SIM Count Per Plan",['carrier','plan'],registry=registry)`

You can create as many metrics as you need. Once you have them created you will want to put the data into them with something like:

`sim_plans.labels(carrier,plan).set(qty_by_plan[plan])`

This will add the correct labels and values to the metric.

Once you have set all your metrics the only thing remaining is to push those metrics from your python script over to the push gateway. That should be done in my case right before the script terminates. You will need to set the host, port, a job name and the registry that contains all of your metrics that you created.

`push_to_gateway(f"{prometheus_host}:{prometheus_port}",job="LteOptimization",registry=registry)`

Now that your metrics have been pushed to prometheus via the push gateway you can either verify the data generated by your job via Prometheus’ web UI on port 9090 or configure Grafana to talk to Prometheus and use Explore.

