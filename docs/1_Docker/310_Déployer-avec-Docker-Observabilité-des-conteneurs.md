---
title: D√©ployer avec Docker Observabilit√© des conteneurs
---

## Objectifs p√©dagogiques
* Comprendre ce qu'on appelle observabilit√©
* Savoir comment utiliser des outils d'observabilit√© avec Docker

---

## Monitorer des conteneurs

- Avec Prometheus pour Docker et Docker Swarm
- Ou bien Netdata, un peu plus joli et configur√© pour monitorer des conteneurs _out-of-the-box_

---

## Instruction `HEALTHCHECK`

`HEALTHCHECK` permet de v√©rifier si l'app contenue dans un conteneur est en bonne sant√©.

```shell
HEALTHCHECK CMD curl --fail http://localhost:5000/health || exit 1
```

```yaml
version: '3.4'
services:
  web:
    image: very-simple-web
    build:
      context: ./
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "80:80"
    healthcheck:
      test: curl --fail http://localhost || exit 1
      interval: 60s
      retries: 5
      start_period: 20s
      timeout: 10s
```
<!-- --- -->

### Du monitoring avec *cAdvisor* et *Prometheus*

Suivre ce tutoriel pour du monitoring des conteneurs Docker : <https://prometheus.io/docs/guides/cadvisor/> -->

<!-- --- -->
## G√©rer les logs des conteneurs

Avec Elasticsearch, Filebeat et Kibana‚Ä¶ gr√¢ce aux labels sur les conteneurs Docker

## Une stack Elastic pour centraliser les logs

**L'utilit√© d'Elasticsearch est que, gr√¢ce √† une configuration tr√®s simple de son module Filebeat, nous allons pouvoir centraliser les logs de tous nos conteneurs Docker.**

Pour ce faire, il suffit d'abord de t√©l√©charger une configuration de Filebeat pr√©vue √† cet effet :

```yaml

filebeat.config:
  modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false

filebeat.autodiscover:
  providers:
    - type: docker
      hints.enabled: true

processors:
- add_cloud_metadata: ~

output.elasticsearch:
  hosts: '${ELASTICSEARCH_HOSTS:elasticsearch:9200}'
  username: '${ELASTICSEARCH_USERNAME:}'
  password: '${ELASTICSEARCH_PASSWORD:}'

```

Rectifions qui poss√®de ce fichier pour satisfaire une contrainte de s√©curit√© de Filebeat :

```shell
sudo chown root filebeat.docker.yml
sudo chmod go-w filebeat.docker.yml
```

Enfin, cr√©ons un fichier `docker-compose.yml` pour lancer une stack Elasticsearch :

```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - 9200:9200
    networks:
      - logging-network

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.5.0
    user: root
    depends_on:
      - elasticsearch
    volumes:
      - type=bind,source=filebeat.docker.yml,target=/usr/share/filebeat/filebeat.yml,read_only=true
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - logging-network
    environment:
      - -strict.perms=false

  kibana:
    image: docker.elastic.co/kibana/kibana:7.5.0
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
    networks:
      - logging-network

networks:
  logging-network:
    driver: bridge
```
<!-- --- -->

D√©marrez les conteneurs.

Dans le conteneur filebeat lancez la commande pour configurer 
```shell
/usr/local/bin/docker-entrypoint setup -E setup.kibana.host=kibana:5601 \
> -E output.elasticsearch.hosts=["elasticsearch:9200"]
```

Il suffit ensuite de :
- se rendre sur Kibana (port `5601`)
- de configurer l'index en tapant `*` dans le champ indiqu√©, de valider
- et de s√©lectionner le champ `@timestamp`, puis de valider.

L'index n√©cessaire √† Kibana est cr√©√©, vous pouvez vous rendre dans la partie Discover √† gauche (l'ic√¥ne boussole üß≠) pour lire vos logs.

Il est temps de faire un petit `docker stats` pour d√©couvrir l'utilisation du CPU et de la RAM de vos conteneurs !

<!-- --- -->
### _Avanc√© :_ Ajouter un n≈ìud Elasticsearch

**√Ä l'aide de la documentation Elasticsearch et/ou en adaptant des bouts de code Docker Compose trouv√©s sur internet, ajoutez et configurez un n≈ìud Elastic.** 

Toujours √† l'aide de la documentation Elasticsearch, v√©rifiez que ce nouveau n≈ìud communique bien avec le premier.
